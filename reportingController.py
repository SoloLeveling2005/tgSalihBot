import asyncio
import csv
import io
import json
import os
import random
import re
import urllib.request
from datetime import datetime, timedelta
from pathlib import Path
from dotenv import load_dotenv
from aiogram import Bot, types
import pandas as pd

load_dotenv()

CHAT_ID = os.getenv("CHAT_ID")
CHAT_PUBLIC_ID =  745

# === –†–∞–±–æ—Ç–∞ —Å –≥–æ—Ä–æ–¥–∞–º–∏ –∏ –µ–≥–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ ===

BEGIN_PUBLICATION_CELL = "N18"
FINISH_PUBLICATION_CELL = "N19"

# –ú–∞—Å—Å–∏–≤ –ª–æ–∫–∞—Ü–∏–π –∏ –∏—Ö –¥–∞–Ω–Ω—ã–µ
LOCATIONS = {
    "kazan": {
        "ru": "–ö–∞–∑–∞–Ω—å",
        "variants_ru": ["–∫–∞–∑–∞–Ω", "–∫–∞–∑–∞–Ω–∏"],
        "exel": {
            "intro": "N2",
            "outro": "N3",
        }
    },
    "novosibirsk": {
        "ru": "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫",
        "variants_ru": ["–Ω–æ–≤–æ—Å–∏–±", "–Ω–æ–≤–æ—Å–∏–±–∏—Ä", "–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–µ"],
        "exel": {
            "intro": "O2",
            "outro": "O3",
        }
    },
    "samara": {
        "ru": "–°–∞–º–∞—Ä–∞",
        "variants_ru": ["—Å–∞–º–∞—Ä", "—Å–∞–º–∞—Ä–µ"],
        "exel": {
            "intro": "P2",
            "outro": "P3",
        }
    },
    "krasnodar": {
        "ru": "–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä",
        "variants_ru": ["–∫—Ä–∞—Å–Ω–æ–¥", "–∫—Ä–∞—Å–Ω–æ–¥–∞—Ä–µ"],
        "exel": {
            "intro": "Q2",
            "outro": "Q3",
        }
    },
    "ekaterinburg": {
        "ru": "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥",
        "variants_ru": ["–µ–∫–∞—Ç–µ—Ä–µ–Ω", "–µ–∫–∞—Ç–µ—Ä–∏–Ω"],
        "exel": {
            "intro": "R2",
            "outro": "R3",
        }
    },
    "moscow_dzerzhinsky": {
        "ru": "–ú–æ—Å–∫–≤–∞ (–î–∑–µ—Ä–∂–∏–Ω—Å–∫–∏–π)",
        "variants_ru": ["–º–æ—Å–∫–≤–∞ (–¥–∑–µ—Ä–∂–∏–Ω—Å–∫–∏–π)"],
        "exel": {
            "intro": "S2",
            "outro": "S3",
        }
    }
}

def detect_location_slug(text: str) -> str | None:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –∫–∞–∫–æ–π-–ª–∏–±–æ –º–µ—Å—Ç–æ –≤ —Å—Ç—Ä–æ–∫–µ (–≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ)."""
    text = text.lower()
    for slug, cfg in LOCATIONS.items():
        if any(v in text for v in cfg["variants_ru"]):
            return slug
    return None

# === ===

# === –•—Ä–∞–Ω–µ–Ω–∏–µ message_id –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ ===

REPORT_FILE = Path("report_data.json")

def load_report_data() -> dict[str, int]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç message_id –ø–æ –∫–∞–∂–¥–æ–º—É –≥–æ—Ä–æ–¥—É –∏–∑ —Ñ–∞–π–ª–∞."""
    if REPORT_FILE.exists():
        return json.loads(REPORT_FILE.read_text(encoding="utf-8"))
    return {}

def save_report_data(data: dict[str, int]) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç message_id –ø–æ –∫–∞–∂–¥–æ–º—É –≥–æ—Ä–æ–¥—É –≤ —Ñ–∞–π–ª."""
    REPORT_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

# === ===

# === –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö —Å —ç–∫—Å–µ–ª—å —Ç–∞–±–ª–∏—Ü—ã ===

def fetch_csv_df() -> pd.DataFrame:
    url = (
        "https://docs.google.com/spreadsheets/"
        "d/1NRGPRwpMyXTe9LhS4adwfPo7nyx68GqweYdAdqo3LpM/"
        "export?format=csv&gid=1265864442"
    )
    try:
        with urllib.request.urlopen(url) as resp:
            if resp.status != 200:
                raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {resp.status}")
            data = io.BytesIO(resp.read())
            df = pd.read_csv(data, encoding='utf-8-sig', header=None)
            df = df.where(pd.notna(df), None)  # ‚Üê –∑–∞–º–µ–Ω—è–µ—Ç –≤—Å–µ NaN –Ω–∞ None

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±—É–∫–≤–µ–Ω–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: A, B, ..., Z, AA, AB, ...
            def colname(n):
                name = ""
                while n >= 0:
                    name = chr(n % 26 + 65) + name
                    n = n // 26 - 1
                return name

            df.columns = [colname(i) for i in range(len(df.columns))]
            return df
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CSV: {e}")
        return pd.DataFrame()
    
def get_excel_cell_value(df: pd.DataFrame, cell: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —è—á–µ–π–∫–∏."""

    def split_cell(cell: str) -> tuple[str, int]:
        match = re.fullmatch(r'([A-Za-z]+)(\d+)', cell.strip())
        if not match:
            raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —è—á–µ–π–∫–∏: {cell}")
        return match.group(1), int(match.group(2)) - 1

    column, row = split_cell(cell)

    if column not in df.columns:
        raise KeyError(f"–ö–æ–ª–æ–Ω–∫–∞ '{column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ DataFrame")

    if row >= len(df):
        raise IndexError(f"–°—Ç—Ä–æ–∫–∞ {row+1} –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞")

    return df[column].iloc[row]

# === ===


def parse_stock_data_from_csv(df: pd.DataFrame) -> dict[str, dict[str, list[dict]]]:
    # –ù–∞–π—Ç–∏ —Å—Ç—Ä–æ–∫—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
    header_idx = None
    for i, row in df.iterrows():
        vals = row.astype(str).str.lower().tolist()
        if "—Å–∫–ª–∞–¥" in vals and "—Å—Ç–∞—Ç—É—Å" in vals:
            header_idx = i
            break
    if header_idx is None:
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏")

    # –í—ã–Ω–µ—Å—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –¥–∞–Ω–Ω—ã–º–∏
    headers = df.iloc[header_idx].tolist()
    data = df.iloc[header_idx+1 : ].copy().reset_index(drop=True)
    data.columns = headers

    result: dict[str, dict[str, list[dict]]] = {}
    for _, row in data.iterrows():
        city   = detect_location_slug(str(row.get("–°–∫–ª–∞–¥", "")).strip())
        status = str(row.get("–°—Ç–∞—Ç—É—Å", "")).lower().strip()
        count  = str(row.get("–ö–æ–ª", "")).strip()

        if not city or not status or count in {"", "0", "0.0"}:
            continue

        def safe_str(val) -> str:
            return str(val).strip() if val is not None else ""

        item = {
            "name":        safe_str(row.get("–ù–∞–∑–≤–∞–Ω–∏–µ")),
            "link":        safe_str(row.get("–°—Å—ã–ª–∫–∞")),
            "desc":        safe_str(row.get("–û–ø–∏—Å–∞–Ω–∏–µ")),
            "count":       safe_str(row.get("–ö–æ–ª")),
            "images":      [u.strip() for u in re.split(r"[,\s]+", safe_str(row.get("–ö–∞—Ä—Ç–∏–Ω–∫–∏"))) if u.strip()],
            "reviews":     safe_str(row.get("–û—Ç–∑—ã–≤—ã –ø–æ –º–æ–¥–µ–ª–∏")),
            "price_avail": safe_str(row.get("–¶–µ–Ω–∞ –∏–∑ –Ω–∞–ª–∏—á–∏—è")),
            "price_order": safe_str(row.get("–¶–µ–Ω–∞ –ø–æ–¥ –∑–∞–∫–∞–∑")),
            "link_order":  safe_str(row.get("–ü–æ–¥ –∑–∞–∫–∞–∑")),
            "arrival":     safe_str(row.get("–ü—Ä–∏–±—ã—Ç–∏–µ")),
        }

        if "–Ω–∞–ª–∏—á–∏" in status:
            status_en = "availability"
        elif "–ø—É—Ç–∏" in status:
            status_en = "onTheWay"
        else:
            continue

        result.setdefault(city, {
            "availability": {"list": []},
            "onTheWay":     {"list": []},
            "intro": "", "outro": ""
        })
        result[city][status_en]["list"].append(item)

        # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –¥–æ, –≤ –Ω–∞—á–∞–ª–µ, –≤ –∫–æ–Ω—Ü–µ –∏ –ø–æ—Å–ª–µ, –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–π.
        result[city]["intro"] = safe_str(get_excel_cell_value(df=df, cell=LOCATIONS[city]["exel"]["intro"]))
        result[city]["outro"] = safe_str(get_excel_cell_value(df=df, cell=LOCATIONS[city]["exel"]["outro"]))

    return result


class Mark2:
    @staticmethod
    def escape(text: str) -> str:
        return re.sub(r'([_*\[\]()~>#+=|{}.!\\-])', r'\\\1', text)

    @classmethod
    def bold(cls, text: str) -> str:
        return f"*{cls.escape(text)}*"

    @classmethod
    def italic(cls, text: str) -> str:
        return f"_{cls.escape(text)}_"

    @classmethod
    def link(cls, text: str, url: str) -> str:
        return f"[{cls.escape(text)}]({cls.escape(url)})"


async def publish_reports(bot: Bot) -> None:
    # —Å–±—Ä–æ—Å–∏–º —Å—Ç–∞—Ä—ã–µ IDs, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å ¬´–Ω–æ–≤—É—é –ø—É–±–ª–∏–∫–∞—Ü–∏—é¬ª
    save_report_data({})
    await update_reports(bot)

def text_new_line(existing: str, addition: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å—Ç—Ä–æ–∫—É –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å –¥–≤—É–º—è –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏, –µ—Å–ª–∏ –æ–±–µ –Ω–µ–ø—É—Å—Ç—ã–µ."""
        if not addition.strip():
            return existing
        if not existing.strip():
            return addition
        return f"{existing}\n\n{addition}"

def split_text_safe(text: str, limit: int = 1024) -> list[str]:
    """–†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏, –Ω–µ –æ–±—Ä—ã–≤–∞—è —Å—Ç—Ä–æ–∫–∏, –Ω–µ –ø—Ä–µ–≤—ã—à–∞—è –ª–∏–º–∏—Ç."""
    lines = text.splitlines(keepends=True)
    parts = []
    current = ""
    for line in lines:
        if len(current) + len(line) > limit:
            parts.append(current.rstrip())
            current = line
        else:
            current += line
    if current.strip():
        parts.append(current.rstrip())
    return parts

async def update_reports(bot: Bot, type_='create') -> None:
    df = fetch_csv_df()
    report_data = parse_stock_data_from_csv(df)
    emojis = ['üöÄüöÄüöÄüöÄüöÄüöÄ', 'üî•üî•üî•üî•üî•üî•']
    thread_id = CHAT_PUBLIC_ID

    begin_text = get_excel_cell_value(df, BEGIN_PUBLICATION_CELL)
    finish_text = get_excel_cell_value(df, FINISH_PUBLICATION_CELL)

    if begin_text:
        await bot.send_message(
            chat_id=CHAT_ID,
            text=Mark2.escape(begin_text),
            parse_mode="MarkdownV2",
            message_thread_id=thread_id
        )
        await bot.send_message(
            chat_id=CHAT_ID,
            text=random.choice(emojis),
            parse_mode="MarkdownV2",
            message_thread_id=thread_id
        )

    for idx, (slug, cfg) in enumerate(LOCATIONS.items(), start=1):
        thread_id = CHAT_PUBLIC_ID
        city_name = cfg["ru"]
        intro = report_data[slug]["intro"]
        outro = report_data[slug]["outro"]

        intro_part = f"\n\n{intro}" if intro else ""
        parts = [Mark2.bold(f"–û—Ç—á—ë—Ç –ø–æ —Å–∫–ª–∞–¥—É ({city_name}){intro_part}")]
        images = []

        for section, title in (("availability", "–ù–∞–ª–∏—á–∏–µ:"), ("onTheWay", "–í –ø—É—Ç–∏:")):
            items = report_data[slug][section]["list"]
            if not items:
                continue
            parts.append(Mark2.bold(title))
            for item in items:
                name = item["name"]
                link = item["link"]
                desc = item["desc"]
                reviews = item["reviews"]
                price_avail = item["price_avail"]
                price_order = item["price_order"]
                link_order = item["link_order"]
                arrival = item["arrival"]
                images.extend(item.get("images", []))

                if link:
                    line = Mark2.link(name, link)
                else:
                    line = Mark2.escape(name)
                    
                if desc:
                    line += f" {Mark2.escape(desc)}"

                if reviews:
                    line += f" {Mark2.link('–û—Ç–∑—ã–≤—ã', reviews)}"

                if price_avail:
                    line += f" –¶–µ–Ω–∞ {Mark2.escape(price_avail)}"

                if link_order and price_order:
                    line += f" {Mark2.link(f'–ü–æ–¥ –∑–∞–∫–∞–∑ {price_order}', link_order)}"
                elif link_order:
                    line += f" {Mark2.link('–ü–æ–¥ –∑–∞–∫–∞–∑', link_order)}"
                elif price_order:
                    line += f" –ü–æ–¥ –∑–∞–∫–∞–∑ {Mark2.escape(price_order)}"

                if arrival:
                    line += f"\n{Mark2.escape(f'–ü—Ä–∏–±—ã—Ç–∏–µ {arrival}')}"

                parts.append(line)

        parts.append(Mark2.escape(outro))
        full_text = "\n\n".join(parts)

        if images:
            caption_chunk, *rest_chunks = split_text_safe(full_text, limit=1024)
            media_group = [
                types.InputMediaPhoto(media=images[0], caption=caption_chunk, parse_mode="MarkdownV2")
            ]
            for url in images[1:10]:
                media_group.append(types.InputMediaPhoto(media=url))
            await bot.send_media_group(
                chat_id=CHAT_ID,
                media=media_group,
                message_thread_id=thread_id
            )

            # –ø–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –æ—Å—Ç–∞—Ç–æ–∫ —Ç–µ–∫—Å—Ç–∞ –≤ –æ–¥–∏–Ω –±–ª–æ–∫ –∏ –ø–æ—Ä–µ–∑–∞—Ç—å –ø–æ 4096
            remaining_text = "\n".join(rest_chunks)
            text_chunks = split_text_safe(remaining_text, limit=4096)
        else:
            text_chunks = split_text_safe(full_text, limit=4096)

        for chunk in text_chunks:
            await bot.send_message(
                chat_id=CHAT_ID,
                text=chunk,
                parse_mode="MarkdownV2",
                message_thread_id=thread_id
            )
            await asyncio.sleep(0.5)

        if idx < len(LOCATIONS):
            await bot.send_message(
                chat_id=CHAT_ID,
                text=random.choice(emojis),
                parse_mode="MarkdownV2",
                message_thread_id=thread_id
            )

    if finish_text:
        await bot.send_message(
            chat_id=CHAT_ID,
            text=Mark2.escape(finish_text),
            parse_mode="MarkdownV2",
            message_thread_id=thread_id
        )


# –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏: –µ—Å–ª–∏ –≥–¥–µ-—Ç–æ –µ—â—ë –∑–æ–≤—ë—Ç—Å—è send_reports
async def send_reports(bot: Bot):
    await update_reports(bot, type_='create')

# if __name__ == "__main__":
#     asyncio.run(update_reports(bot=None))